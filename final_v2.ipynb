{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final-v2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgumi/seminararbeit/blob/master/final_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIo03i7VErog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import randint, uniform\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import json\n",
        "import urllib.request\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import f1_score, make_scorer, confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from collections import Counter\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(style=\"whitegrid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65g0sBlAx75d",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsy9uvArFBJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def barplot(df, column):\n",
        "  '''\n",
        "    creates a barplot for the given data in df[column]\n",
        "    -> shows the dustribution the successrate of the given data\n",
        "    createa s boxplot for the given data in df[column]\n",
        "  '''\n",
        "  # get the count of each distinct values in series\n",
        "  value_counts = pd.DataFrame()\n",
        "  value_counts= df.loc[:, column].value_counts()\n",
        "  value_counts_success = df[( df['success'] == 'Yes')].loc[:, column].value_counts()\n",
        "  # create a plot for the bar graph\n",
        "\n",
        "\n",
        "  sns.set_color_codes(\"pastel\")\n",
        "  sns.barplot(value_counts.index, value_counts.values, color=\"b\",\n",
        "              label=\"Total\")\n",
        "\n",
        "  sns.set_color_codes(\"muted\")\n",
        "  sns.barplot(value_counts_success.index, value_counts_success.values,\n",
        "              color=\"b\", label=\"Successful\")\n",
        "  \n",
        "\n",
        "  plt.legend(ncol=2, loc=\"upper right\", frameon=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a8uQAdvOVte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_eurostoxx= pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/eurostoxx_ref.csv', \n",
        "    index_col=['index'], parse_dates=['date'])\n",
        "\n",
        "df_eurostoxx = df_eurostoxx[(df_eurostoxx['date'].dt.year >= 2007)]\n",
        "\n",
        "def get_eurostoxx(date):\n",
        "  for i in range(0, len(df_eurostoxx)):\n",
        "\n",
        "    if date >= df_eurostoxx['date'].iloc[i]:\n",
        "      last = df_eurostoxx['value'].iloc[i]\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS4n-_a4OgdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.financialresearch.gov/financial-stress-index/\n",
        "df_fsi= pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/fsi_ref.csv', \n",
        "    index_col=['index'], parse_dates=['Date'])\n",
        "\n",
        "df_fsi = df_fsi[(df_fsi['Date'].dt.year >= 2007)]\n",
        "\n",
        "def get_fsi(date):\n",
        "  for i in range(0, len(df_fsi)):\n",
        "\n",
        "    if date >= df_fsi['Date'].iloc[i]:\n",
        "      # Possible values: [OFR FSI, Credit, Equity valuation, Safe assets, Funding, Volatility]\n",
        "      last = df_fsi['OFR FSI'].iloc[i]\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33cyR0R7Llxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cpi = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/cpi_monthly_ref.csv', \n",
        "    index_col=['index'], parse_dates=['date'])\n",
        "\n",
        "df_cpi = df_cpi[(df_cpi['date'].dt.year >= 2007)]\n",
        "\n",
        "def get_cpi(date):\n",
        "  for i in range(0, len(df_cpi)):\n",
        "\n",
        "    if date >= df_cpi['date'].iloc[i]:\n",
        "      last = df_cpi['value'].iloc[i]\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYAngATPuYD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ltz = {}\n",
        "with urllib.request.urlopen(\"https://raw.githubusercontent.com/rgumi/seminararbeit_src/master/refined/leitzinsen_eu.json\") as url:\n",
        "    tmp_ltz = json.loads(url.read().decode())\n",
        "for key in tmp_ltz.keys():\n",
        "  ltz[dt.datetime.strptime(key, '%d-%m-%Y')] = tmp_ltz[key]\n",
        "sorted_ltz = {k: ltz[k] for k in sorted(ltz)}\n",
        "\n",
        "def get_base_rate(date):\n",
        "  for key, val in sorted_ltz.items():\n",
        "    if date >= key:\n",
        "      last = val\n",
        "      continue\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8rRxxjwEm-M",
        "colab_type": "code",
        "outputId": "e69e5599-879d-4857-ebea-caae67d1b380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "dataset = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/saschaschworm/big-data-and-data-science/master/datasets/prediction-challenge/dataset.csv', \n",
        "    index_col='identifier', parse_dates=['date'])\n",
        "\n",
        "# insignificant because it is equally distributed between Mo to Fr\n",
        "dataset.insert(len(dataset.columns) -1, \"weekday\", dataset.date.dt.weekday)\n",
        "# grouped by quarter (reduce overcomplexity)\n",
        "dataset.insert(len(dataset.columns) -1, \"month\", dataset.date.dt.month)\n",
        "# partially replaced by financial measures\n",
        "dataset.insert(len(dataset.columns) -1, \"year\", dataset.date.dt.year)\n",
        "\n",
        "# significant because it can give insight on the intra-month distribution\n",
        "dataset.insert(len(dataset.columns) -1, \"day\", dataset.date.dt.day)\n",
        "# significant because it can give insight on the intra-year distribution\n",
        "dataset.insert(len(dataset.columns) -1, \"quarter\", dataset.date.dt.quarter)\n",
        "\n",
        "# Financial Measures\n",
        "# give an insight in status of the financial markets\n",
        "dataset.insert(len(dataset.columns)-1, \"base_rate\", dataset['date'].apply(get_base_rate))\n",
        "dataset.insert(len(dataset.columns)-1, \"cpi\", dataset['date'].apply(get_cpi))\n",
        "dataset.insert(len(dataset.columns)-1, \"fsi\", dataset['date'].apply(get_fsi))\n",
        "dataset.insert(len(dataset.columns)-1, \"eurostoxx\", dataset['date'].apply(get_eurostoxx))\n",
        "\n",
        "# replaced by the features above\n",
        "dataset = dataset.drop('date', axis=1)\n",
        "\n",
        "# To increase gap between 0, 1, ... values (existent contact) and -1 (non-existent)\n",
        "dataset.loc[dataset['days_since_last_contact'] == -1, 'days_since_last_contact'] = 10000\n",
        "\n",
        "dataset.columns"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'marital_status', 'education', 'job', 'credit_default',\n",
              "       'housing_loan', 'personal_loan', 'communication_type',\n",
              "       'n_contacts_campaign', 'days_since_last_contact', 'n_contacts_before',\n",
              "       'previous_conversion', 'duration', 'weekday', 'month', 'year', 'day',\n",
              "       'quarter', 'base_rate', 'cpi', 'fsi', 'eurostoxx', 'success'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xWHtEZpF_l-",
        "colab_type": "code",
        "outputId": "e92f4b6d-2847-435c-9882-6795c7a0c551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "barplot(dataset, 'weekday')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD7CAYAAABnoJM0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiImpyAQETE5BYGIiMn9Hzzdzb1s3aurAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chldv7-yEP04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_features = ['day' ,'quarter', 'education', 'job', 'age', \n",
        "             'previous_conversion', 'n_contacts_before',\n",
        "             'n_contacts_campaign', 'days_since_last_contact',\n",
        "             'marital_status', 'credit_default', 'duration',\n",
        "             'housing_loan', 'personal_loan', 'base_rate',\n",
        "             'eurostoxx', 'fsi', 'cpi', 'communication_type']\n",
        "\n",
        "categorical_features = ['education', 'job', 'previous_conversion',\n",
        "                        'marital_status', 'quarter', 'credit_default',\n",
        "                        'personal_loan', 'housing_loan', 'communication_type']\n",
        "\n",
        "numerical_features = ['n_contacts_campaign', 'duration', \n",
        "                      'age', 'cpi', 'days_since_last_contact',\n",
        "                      'base_rate', 'eurostoxx', 'fsi', 'day',\n",
        "                      'n_contacts_before']\n",
        "\n",
        "\n",
        "X = dataset[all_features]\n",
        "y = dataset['success']\n",
        "# Label Encoded\n",
        "y = y.apply(lambda x: 1 if x == \"Yes\" else 0)\n",
        "\n",
        "# --- \n",
        "\n",
        "# One-Hot Encoded\n",
        "for item in categorical_features:\n",
        "  try:\n",
        "    encoded = pd.get_dummies(X[item], prefix=item)\n",
        "    X.drop(item, axis=1, inplace=True)\n",
        "    X = X.join(encoded)\n",
        "  except Exception as e:\n",
        "    print(\"Something went wrong?!\")\n",
        "    print(e)\n",
        "    continue\n",
        "\n",
        "# Normalization \n",
        "scaler = MinMaxScaler()\n",
        "X[numerical_features] = scaler.fit_transform(X[numerical_features])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFlNcu4m2foR",
        "colab_type": "text"
      },
      "source": [
        "# Model Selection\n",
        "\n",
        "The target variable of this problem is binary (Yes/No). Therefore, the model needs to be able to handle binary classification. The following models were selected for preselection:\n",
        "1. Logistic Regression\n",
        "\n",
        "2. Decision Tree (Random Forest)\n",
        "\n",
        "3. Extreme Gradiant Boosting Classification (XGBClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAhVa1TIl0FZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function which takes a model and the training data to run a \n",
        "# cross_validate with the f1-scorer\n",
        "def validate_model(model, X, y):\n",
        "  scoring=custom_scorer\n",
        "  # performs a 10-fold-crossvalidate 3 times\n",
        "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, \n",
        "                               random_state=1909)\n",
        "  scores = cross_validate(model, X, y, scoring=scoring, cv=cv, \n",
        "                          n_jobs=-1, return_train_score=True)\n",
        "  train_score = np.mean(scores[\"train_score\"])*100\n",
        "  test_score = np.mean(scores[\"test_score\"])*100\n",
        "  print(f'Mean F1 Score of {str(model).split(\"(\")[0]}: {train_score:.2f}/{test_score:.2f}\\n')\n",
        "  return {\n",
        "      'train': train_score,\n",
        "      'test': test_score\n",
        "      }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuU0JXcs2faK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "87d59f62-f409-4198-fe3e-a216bae0fe6a"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "custom_scorer = make_scorer(f1_score, pos_label=1)\n",
        "\n",
        "# The evaluation is done by running all models with the same preprocessed datasets\n",
        "# Every model will use their default hyperparameters. No optimization has been conducted\n",
        "# The evaluation is done with the F1 Score for all models using \n",
        "# a k-fold cross-validation (RepeatedStratifiedKFold)\n",
        "\n",
        "model = LogisticRegression() # default hyperparameters\n",
        "print(f'Evaluating Model: {str(model).split(\"(\")[0]}')\n",
        "lgr_score = validate_model(model, X, y)\n",
        "\n",
        "model = RandomForestClassifier() # default hyperparameters\n",
        "print(model)\n",
        "print(f'Evaluating Model: {str(model).split(\"(\")[0]}')\n",
        "rfc_score = validate_model(model, X, y)\n",
        "\n",
        "model = XGBClassifier() # default hyperparameters\n",
        "print(model)\n",
        "print(f'Evaluating Model: {str(model).split(\"(\")[0]}')\n",
        "xgbc_score = validate_model(model, X, y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating Model: LogisticRegression\n",
            "Mean F1 Score of LogisticRegression: 48.28/48.06\n",
            "\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "Evaluating Model: RandomForestClassifier\n",
            "Mean F1 Score of RandomForestClassifier: 99.99/53.39\n",
            "\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, verbosity=1)\n",
            "Evaluating Model: XGBClassifier\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean F1 Score of XGBClassifier: 58.42/56.59\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P7d4DFsXiyB",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qi7nwcigeyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_scorer = make_scorer(f1_score, pos_label=1)\n",
        "\n",
        "def gridsearch(model, param_grid, X, y):\n",
        "  '''\n",
        "  Takes a model, param_grid and datasets \n",
        "  to perform a grid search\n",
        "  '''\n",
        "  search = GridSearchCV(model, param_grid=param_grid, scoring=custom_scorer,\n",
        "                    n_jobs=-1, cv=4, refit=True, error_score=0).fit(X, y)\n",
        "\n",
        "  print(f'Optimal parameters: {search.best_params_}')\n",
        "  print(f'Best Score: {search.best_score_}')\n",
        "  return search.best_params_\n",
        "\n",
        "def randsearch(model, param_distr, X, y):\n",
        "  '''\n",
        "  Takes a model, param_distribution and datasets \n",
        "  to perform a randomized search\n",
        "  '''\n",
        "  search = RandomizedSearchCV(model, param_distributions=param_distr, \n",
        "                              n_iter=10, scoring=custom_scorer, n_jobs=-1, \n",
        "                              cv=10, random_state=1909).fit(X, y)\n",
        "\n",
        "  print(f'Optimal parameters: {search.best_params_}')\n",
        "  print(f'Best Score: {search.best_score_}')\n",
        "  return search.best_params_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPKfRKY2I3OE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# basis hyperparams\n",
        "hyperparams = {\n",
        "    'scale_pos_weight': 8, # = sum(negative instances) / sum(positive instances) for imbalanced datasets\n",
        "    'gamma': 0, # minimum loss reduction needed to split a leaf node \n",
        "    'booster': 'gbtree', # => Decision Tree\n",
        "    'objective': 'binary:logistic', # Outputs the Probability computed using a logistic function \n",
        "    'silent': True, \n",
        "    'missing': None,\n",
        "    'nthread': -1,\n",
        "    'random_state': 1909, # => Reproducibility\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgpktDV1hUpo",
        "colab_type": "code",
        "outputId": "cac1f2d5-57fb-4ee0-beb2-6477082a41d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from scipy.stats import randint, uniform\n",
        "\n",
        "custom_scorer = make_scorer(f1_score, pos_label=1)\n",
        "\n",
        "n_estimators = randint(80, 150) # default 100\n",
        "max_depth = randint(8, 50) # default 6\n",
        "learning_rate = uniform(0.005, 0.3) # default 0.3\n",
        "\n",
        "# regularization\n",
        "gamma = randint(0, 5) # default 0\n",
        "reg_lambda = randint(1, 5) # default 1\n",
        "\n",
        "# subsampling\n",
        "colsample_bynode = uniform(0.25, 1) # default 1\n",
        "colsample_bylevel = uniform(0.25, 1) # default 1\n",
        "colsample_bytree = uniform(0.25, 1) # default 1\n",
        "subsample = uniform(0.25, 1) # default 1\n",
        "base_score = uniform(0.2, 0.8) # default 0.5\n",
        "min_child_weight = uniform(0.2, 1) # default 1\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': n_estimators, # how many decision trees should be built\n",
        "    'max_depth': max_depth, # how many levels are allowed in a tree\n",
        "    'learning_rate': learning_rate, # eta of the gradient decent (step size)\n",
        "    'subsample': subsample, # % of randomly sampled training data\n",
        "    'colsample_bynode': colsample_bynode, # % of randomly sampled features per node\n",
        "    'colsample_bylevel': colsample_bylevel, # % of randomly sampled features per level\n",
        "    'colsample_bytree': colsample_bytree, # % of randomly sampled features per tree\n",
        "    'base_score': base_score, # the base score (weight) every feature has at the start\n",
        "    'min_child_weight': min_child_weight, # minimum needed sum of weights to split a leaf node\n",
        "    # 'reg_lambda': reg_lambda, # L2 Regularization\n",
        "    # 'gamma': gamma, # minimum loss reduction needed to further split a leaf node \n",
        "}\n",
        "\n",
        "best_params = randsearch(XGBClassifier(**hyperparams), \n",
        "                         param_distr=param_grid, X=X, y=y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimal parameters: {'base_score': 0.9002877650727912, 'colsample_bylevel': 0.9652028644880783, 'colsample_bynode': 0.3159502128331547, 'colsample_bytree': 0.8328197200519124, 'learning_rate': 0.11018223430025721, 'max_depth': 26, 'min_child_weight': 0.39171405586056623, 'n_estimators': 113, 'subsample': 0.4755162022020196}\n",
            "Best Score: 0.6076429128687069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkwIIGQLlgM0",
        "colab_type": "code",
        "outputId": "5bf84e15-8848-4f5d-c622-6c8e8b7a650f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "# with best parameters from optimization\n",
        "f_hyperparams = {**hyperparams, **{\n",
        "    'learning_rate': best_params['learning_rate'],\n",
        "    'n_estimators': best_params['n_estimators'],\n",
        "    'max_depth': best_params['max_depth'],\n",
        "    'colsample_bylevel': best_params['colsample_bylevel'],\n",
        "    'colsample_bynode': best_params['colsample_bynode'],\n",
        "    'colsample_bytree': best_params['colsample_bytree'],\n",
        "    'subsample': best_params['subsample'],\n",
        "    'base_score': best_params['base_score'],\n",
        "    'min_child_weight': best_params['min_child_weight'],\n",
        "    }\n",
        "}\n",
        "\n",
        "model = XGBClassifier(**f_hyperparams)\n",
        "print(model)\n",
        "validate_model(model, X, y)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.9002877650727912, booster='gbtree',\n",
            "              colsample_bylevel=0.9652028644880783,\n",
            "              colsample_bynode=0.3159502128331547,\n",
            "              colsample_bytree=0.8328197200519124, gamma=0,\n",
            "              learning_rate=0.11018223430025721, max_delta_step=0, max_depth=26,\n",
            "              min_child_weight=0.39171405586056623, missing=None,\n",
            "              n_estimators=113, n_jobs=1, nthread=-1,\n",
            "              objective='binary:logistic', random_state=1909, reg_alpha=0,\n",
            "              reg_lambda=1, scale_pos_weight=8, seed=None, silent=True,\n",
            "              subsample=0.4755162022020196, verbosity=1)\n",
            "Mean F1 Score of XGBClassifier: 99.14/60.71\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': 60.70727332193293, 'train': 99.13929451164643}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM7mwuyO8O1u",
        "colab_type": "text"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43J6FNEL8OUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_dataset = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/saschaschworm/big-data-and-data-science/master/datasets/prediction-challenge/prediction-dataset.csv', \n",
        "    index_col='identifier', parse_dates=['date'])\n",
        "\n",
        "# insignificant because weekday is equally distributed\n",
        "prediction_dataset.insert(len(prediction_dataset.columns) -1, \"weekday\", prediction_dataset.date.dt.weekday)\n",
        "\n",
        "prediction_dataset.insert(len(prediction_dataset.columns) -1, \"day\", prediction_dataset.date.dt.day)\n",
        "\n",
        "prediction_dataset.insert(len(prediction_dataset.columns) -1, \"month\", prediction_dataset.date.dt.month)\n",
        "\n",
        "prediction_dataset.insert(len(prediction_dataset.columns) -1, \"year\", prediction_dataset.date.dt.year)\n",
        "\n",
        "prediction_dataset.insert(len(prediction_dataset.columns) -1, \"quarter\", prediction_dataset.date.dt.quarter)\n",
        "\n",
        "# financial measures\n",
        "prediction_dataset.insert(len(prediction_dataset.columns)-1, \"base_rate\", prediction_dataset['date'].apply(get_base_rate))\n",
        "prediction_dataset.insert(len(prediction_dataset.columns)-1, \"cpi\", prediction_dataset['date'].apply(get_cpi))\n",
        "prediction_dataset.insert(len(prediction_dataset.columns)-1, \"fsi\", prediction_dataset['date'].apply(get_fsi))\n",
        "prediction_dataset.insert(len(prediction_dataset.columns)-1, \"eurostoxx\", prediction_dataset['date'].apply(get_eurostoxx))\n",
        "\n",
        "prediction_dataset = prediction_dataset.drop('date', axis=1)\n",
        "prediction_dataset.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiUOM5Im8MiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_pred = prediction_dataset[all_features]\n",
        "\n",
        "for item in categorical_features:\n",
        "  try:\n",
        "    encoded = pd.get_dummies(X_pred[item], prefix=item)\n",
        "    X_pred.drop(item, axis=1, inplace=True)\n",
        "    X_pred = X_pred.join(encoded)\n",
        "  except Exception as e:\n",
        "    print(\"Something went wrong?!\")\n",
        "    print(e)\n",
        "    continue\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_pred[numerical_features] = scaler.fit_transform(X_pred[numerical_features])\n",
        "\n",
        "# Add missing features to the prediction dataset at the position it has\n",
        "# in the training dataset\n",
        "for feature in X.columns:\n",
        "  if not feature in X_pred.columns:\n",
        "    print(f' X_pred is missing {feature}')\n",
        "    X_pred.insert(X.columns.tolist().index(feature), feature, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsSPk1JUJzOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mountpath = \"/content/drive\"\n",
        "from google.colab import drive\n",
        "drive.mount(mountpath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzbQ05JN8KOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = XGBClassifier(**f_hyperparams)\n",
        "model.fit(X, y)\n",
        "predictions = model.predict(X_pred)\n",
        "\n",
        "submission = pd.DataFrame(\n",
        "    predictions, index=X_pred.index, columns=['prediction'])\n",
        "\n",
        "matriculation_number = '465527'\n",
        "\n",
        "submission.to_csv(\n",
        "    f'{mountpath}/My Drive/seminararbeit/result/submission-{matriculation_number}.csv', index_label='identifier')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}