{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seminarpaper",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgumi/seminararbeit/blob/master/seminarpaper-0.0.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rrQrTCrhbO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pre processing\n",
        "from scipy.stats import randint, uniform\n",
        "import pandas as pd \n",
        "pd.options.mode.chained_assignment = None\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "import datetime as dt\n",
        "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "#import xgboost as xgb\n",
        "#from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_validate, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, make_scorer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOhAuQG8tzj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shows all unique values for each column\n",
        "def print_columns_unique(df):\n",
        "  for (name, data) in df.iteritems():\n",
        "    print(name, data.unique())\n",
        "\n",
        "# Preprocessing: Date\n",
        "def get_info_from_date(df):\n",
        "    df['year'] = df['date'].dt.year\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['day'] = df['date'].dt.day\n",
        "    # 6=Sonntag, 5=Samstag, 4=Freitag (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.dayofweek.html)\n",
        "    # set True wenn Mo-Fr ist\n",
        "    #df['is_weekday'] = df['date'].dt.dayofweek < 5\n",
        "    df.drop(['date'], axis=1, inplace=True)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAW5xaxrnqxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setup\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/saschaschworm/big-data-and-data-science/master/datasets/prediction-challenge/dataset.csv',\n",
        "                   index_col='identifier', parse_dates=['date'])\n",
        "\n",
        "# print_columns_unique(data)\n",
        "\n",
        "X, y = data.iloc[1:-1], data['success']\n",
        "\n",
        "# Date Preprocessing\n",
        "X = get_info_from_date(X)\n",
        "\n",
        "\n",
        "hyperparams = {'random_state': 1909}\n",
        "\n",
        "model = RandomForestClassifier(**hyperparams)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9mxt-2Uk_5V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "6bece75a-82c6-4a74-bdb8-1471d8bc2f05"
      },
      "source": [
        "# Drop not needed features to reduce complexity and overfitting\n",
        "X.drop(['communication_type'], axis=1, inplace=True)\n",
        "print(X.shape, y.shape)\n",
        "print_columns_unique(X)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(37067, 16) (37069,)\n",
            "age [32 68 39 30 48 28 42 35 59 40 58 56 49 41 36 53 34 51 50 44 47 29 45 38\n",
            " 23 37 33 25 55 26 54 31 27 46 57 72 60 62 43 70 52 22 71 21 61 67 24 95\n",
            " 73 63 20 83 18 85 81 19 98 82 79 76 80 84 66 64 74 65 88 75 69 86 78 77\n",
            " 17 92 89 94 87 91]\n",
            "marital_status ['single' 'married' 'divorced' 'unknown']\n",
            "education ['University' 'Middle School' 'High School' 'Professional Training'\n",
            " 'Elementary School' 'Unknown' 'Illiterate']\n",
            "job ['Student' 'Pensioner' 'Administrator' 'Technician' 'Blue-collar worker'\n",
            " 'Self-employed' 'Unemployed' 'Manager' 'Service provider' 'Housemaid'\n",
            " 'Founder' 'Unknown']\n",
            "credit_default ['No' 'Unknown' 'Yes']\n",
            "housing_loan ['Yes' 'No' 'Unknown']\n",
            "personal_loan ['No' 'Unknown' 'Yes']\n",
            "n_contacts_campaign [ 1  3  2  6  4  7 14  9  8 23  5 26 10 11 12 18 24 13 16 21 31 35 27 22\n",
            " 19 29 15 20 32 17 43 28 33 40 37 42 30 25 56 41 34 39]\n",
            "days_since_last_contact [-1  6  7  0  3 14  2  1  4 13  5 11 10  9 12  8 17 16 15 18 26 19 22 27\n",
            " 25 21]\n",
            "n_contacts_before [0 1 2 3 4 5 6 7]\n",
            "previous_conversion ['Inexistent' 'Failed' 'Successful']\n",
            "duration [ 147  139  127 ... 1432 2653 1548]\n",
            "success ['No' 'Yes']\n",
            "year [2008 2009 2010]\n",
            "month [ 5  9  8  7 11 10  4  6 12]\n",
            "day [ 8  4  6  7  3 30  1  5  9  2 31 28 29 10 27]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WydWwqETnep3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pipeline\n",
        "categorical_features = ['marital_status', 'education', 'job', 'credit_default', 'housing_loan', 'personal_loan', 'previous_conversion']\n",
        "numeric_features = ['age', 'n_contacts_campaign', 'days_since_last_contact', 'n_contacts_before', 'duration']\n",
        "\n",
        "numeric_transformer = Pipeline([\n",
        "    ('scaler', MinMaxScaler()),\n",
        "])\n",
        "categorical_transformer = Pipeline ([\n",
        "    ('onehotencoder', OrdinalEncoder())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('n_transformer', numeric_transformer, numeric_features),\n",
        "    ('c_transformer', categorical_transformer, categorical_features),\n",
        "])\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', model)\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8h4MCjsnXBN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "ff82c88c-b057-4c91-d154-a366bd521ee8"
      },
      "source": [
        "# randomized hyperparameter search\n",
        "custom_scorer = make_scorer(f1_score, pos_label='Yes')\n",
        "n_estimators = randint(100, 600)\n",
        "max_depth = randint(50, 400)\n",
        "\n",
        "param_distributions = { 'model__n_estimators': n_estimators, \n",
        "                        'model__max_depth': max_depth\n",
        "}\n",
        "\n",
        "rs = RandomizedSearchCV(pipeline, param_distributions=param_distributions, n_iter=5,\n",
        "                       scoring=custom_scorer, n_jobs=-1, iid=False, cv=10, random_state=1909)\n",
        "\n",
        "rs = rs.fit(X, y)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-07ad49ca6e7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                        scoring=custom_scorer, n_jobs=-1, iid=False, cv=10, random_state=1909)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m         \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \"\"\"\n\u001b[1;32m    247\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [37067, 37069]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGEibMYUnRQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run optimized model\n",
        "hyperparams = {'n_estimators': rs.best_params_['model__n_estimators'], \n",
        "               'criterion': 'gini', \n",
        "               'max_depth': rs.best_params_['model__max_depth'],\n",
        "               'min_samples_split': 2,\n",
        "               'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto',\n",
        "               'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None,\n",
        "               'bootstrap': True, 'oob_score': False, 'n_jobs': None, 'random_state': 1909,\n",
        "               'verbose': 0, 'warm_start': False, 'class_weight': None\n",
        "               }\n",
        "\n",
        "\n",
        "model = RandomForestClassifier(**hyperparams)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor), \n",
        "    ('model', model)\n",
        "])\n",
        "pipeline.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRYFhgewnOFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validating\n",
        "res_cv = cross_validate(pipeline, X, y, scoring=custom_scorer, cv=10, return_train_score=True)\n",
        "res_f1_tr = np.mean(res_cv['train_score']) * 100\n",
        "res_f1_te = np.mean(res_cv['test_score']) * 100\n",
        "print(hyperparams)\n",
        "result = f'Average F1 on Training and Test Sets: {res_f1_tr:.2f}%/{res_f1_te:.2f}%'\n",
        "print(result)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4tOSNqMdCvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# persists results for later analysis\n",
        "import json\n",
        "from datetime import datetime as dt\n",
        "\n",
        "mountpath = \"/content/drive\"\n",
        "from google.colab import drive\n",
        "drive.mount(mountpath)\n",
        "\n",
        "resultJSON = {\n",
        "    \"date\": dt.now().strftime(\"%d.%m.%Y, %H:%M:%S\"),\n",
        "    \"result\": result,\n",
        "    \"hyperparams\": hyperparams\n",
        "}\n",
        "\n",
        "with open(mountpath + '/My Drive/seminararbeit/results.txt', 'a') as file:\n",
        "  file.write(str(resultJSON) + '\\n')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}