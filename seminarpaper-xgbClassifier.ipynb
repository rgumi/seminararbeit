{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seminarpaper",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgumi/seminararbeit/blob/master/seminarpaper-xgbClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rrQrTCrhbO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import randint\n",
        "from datetime import date as d\n",
        "from datetime import datetime as dt\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import json\n",
        "import urllib.request\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import cross_validate, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, make_scorer\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFqbnUk61S-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mountpath = \"/content/drive\"\n",
        "from google.colab import drive\n",
        "drive.mount(mountpath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7Q9sbYE1As2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ltz = {}\n",
        "with urllib.request.urlopen(\"https://raw.githubusercontent.com/rgumi/seminararbeit/master/leitzinsen_eu.json\") as url:\n",
        "    tmp_ltz = json.loads(url.read().decode())\n",
        "for key in tmp_ltz.keys():\n",
        "  ltz[dt.datetime.strptime(key, '%d-%m-%Y')] = tmp_ltz[key]\n",
        "sorted_ltz = {k: ltz[k] for k in sorted(ltz)}\n",
        "print(sorted_ltz)\n",
        "\n",
        "def get_leitzins(date):\n",
        "  for key, val in sorted_ltz.items():\n",
        "    if date >= key:\n",
        "      last = val\n",
        "      continue\n",
        "    return last\n",
        "\n",
        "def derive_age(age):\n",
        "  if age <= 18:\n",
        "    return 'underage'\n",
        "  if age <=30:\n",
        "    return 'younger'\n",
        "  if age <=60:\n",
        "    return 'older'\n",
        "  if age > 60:\n",
        "    return 'old'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOhAuQG8tzj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shows all unique values for each column\n",
        "def print_columns_unique(df):\n",
        "  for (name, data) in df.iteritems():\n",
        "    print(name, data.unique())\n",
        "\n",
        "# Preprocessing: Date\n",
        "def get_info_from_date(df):\n",
        "  df['year'] = df.loc[:, 'date'].dt.year\n",
        "  df['month'] = df.loc[:, 'date'].dt.month\n",
        "  df['day'] = df.loc[:, 'date'].dt.day\n",
        "  # get quarter \n",
        "  df['quarter'] = df.loc[:, 'month'] // 4 + 1\n",
        "  # 6=Sonntag, 5=Samstag, 4=Freitag (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.dayofweek.html)\n",
        "  # set True wenn Mo-Fr ist\n",
        "  #df['is_weekday'] = df['date'].dt.dayofweek < 5\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAW5xaxrnqxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setup\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/saschaschworm/big-data-and-data-science/master/datasets/prediction-challenge/dataset.csv',\n",
        "                   index_col='identifier', parse_dates=['date'])\n",
        "\n",
        "X, y = data.iloc[:, 0:-1], data.loc[:, 'success']\n",
        "\n",
        "# Date Preprocessing\n",
        "X = get_info_from_date(X)\n",
        "X['age_group'] = X['age'].apply(derive_age)\n",
        "X['leitzins'] = X['date'].apply(get_leitzins)\n",
        "\n",
        "\n",
        "hyperparams = { 'seed': 1909,\n",
        "                'nthread': -1\n",
        "               }\n",
        "\n",
        "model = xgb.XGBClassifier(**hyperparams)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9mxt-2Uk_5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop not needed features to reduce complexity and overfitting\n",
        "X.drop(['communication_type'], axis=1, inplace=True)\n",
        "X.drop(['date'], axis=1, inplace=True)\n",
        "print(X.shape, y.shape)\n",
        "X.to_csv(mountpath + '/My Drive/seminararbeit/tmp.csv')\n",
        "# print_columns_unique(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WydWwqETnep3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pipeline\n",
        "categorical_features = ['age_group', 'quarter', 'marital_status', 'education', 'job', 'credit_default', 'housing_loan', 'personal_loan', 'previous_conversion']\n",
        "numeric_features = ['leitzins', 'day', 'month', 'year', 'age', 'n_contacts_campaign', 'days_since_last_contact', 'n_contacts_before', 'duration']\n",
        "\n",
        "numeric_transformer = Pipeline([\n",
        "    ('scaler', MinMaxScaler()),\n",
        "])\n",
        "categorical_transformer = Pipeline ([\n",
        "    ('onehotencoder', OrdinalEncoder())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('n_transformer', numeric_transformer, numeric_features),\n",
        "    ('c_transformer', categorical_transformer, categorical_features),\n",
        "])\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', model)\n",
        "])\n",
        "\n",
        "custom_scorer = make_scorer(f1_score, pos_label='Yes')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8h4MCjsnXBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# randomized hyperparameter optimization\n",
        "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
        "\n",
        "n_estimators = randint(50, 400)\n",
        "max_depth = randint(1, 100)\n",
        "learning_rate = 0.2\n",
        "min_child_weight = 0.2\n",
        "gamma = 0.8\n",
        "colsample_bytree = 0.8\n",
        "colsample_bylevel = 1\n",
        "subsample = 0.8\n",
        "scale_pos_weight = 1\n",
        "\n",
        "param_distributions = {'model__n_estimators': n_estimators, \n",
        "                       'model__max_depth': max_depth\n",
        "                       }\n",
        "\n",
        "rs = RandomizedSearchCV(pipeline, param_distributions=param_distributions, n_iter=5,\n",
        "                       scoring=custom_scorer, n_jobs=-1, cv=10, random_state=1909)\n",
        "\n",
        "rs = rs.fit(X, y)\n",
        "print(rs.best_params_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGEibMYUnRQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run optimized model\n",
        "hyperparams = {'seed': 1909,\n",
        "               'learning_rate': learning_rate,\n",
        "               'min_child_weight': min_child_weight,\n",
        "               'scale_pos_weight': scale_pos_weight,\n",
        "               'colsample_bylevel': colsample_bylevel,\n",
        "               'colsample_bytree': colsample_bytree,\n",
        "               'max_depth': rs.best_params_['model__max_depth'],\n",
        "               'n_estimators': rs.best_params_['model__n_estimators'],\n",
        "               'gamma': gamma,\n",
        "               'subsample': subsample,\n",
        "               'base_score': 0.5,\n",
        "               'nthread': -1,\n",
        "               'booster': 'gbtree',\n",
        "               'objective': 'binary:logistic',\n",
        "               'silent': True,\n",
        "               'reg_lambda': 1,\n",
        "               'missing': None,\n",
        "               'max_delta_step': 0,\n",
        "            }\n",
        "\n",
        "model = xgb.XGBClassifier(**hyperparams)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor), \n",
        "    ('model', model)\n",
        "])\n",
        "pipeline.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRYFhgewnOFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validating\n",
        "res_cv = cross_validate(pipeline, X, y, scoring=custom_scorer, cv=10, return_train_score=True)\n",
        "res_f1_tr = np.mean(res_cv['train_score']) * 100\n",
        "res_f1_te = np.mean(res_cv['test_score']) * 100\n",
        "print(hyperparams)\n",
        "result = f'Average F1 on Training and Test Sets: {res_f1_tr:.2f}%/{res_f1_te:.2f}%'\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4tOSNqMdCvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# persists results for later analysis\n",
        "\n",
        "resultJSON = {\n",
        "    \"date\": dt.now().strftime(\"%d.%m.%Y, %H:%M:%S\"),\n",
        "    \"result\": result,\n",
        "    \"hyperparams\": hyperparams\n",
        "}\n",
        "\n",
        "with open(mountpath + '/My Drive/seminararbeit/results-xgb.txt', 'a') as file:\n",
        "  file.write(str(resultJSON) + '\\n')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}